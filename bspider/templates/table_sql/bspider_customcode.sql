SET FOREIGN_KEY_CHECKS = 0;

DROP table if exists bspider_customcode;
CREATE TABLE `bspider_customcode` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '自增id',
  `name` varchar(100) NOT NULL COMMENT '方法类名',
  `description` longtext NOT NULL COMMENT '代码功能的简要介绍',
  `type` varchar(100) NOT NULL COMMENT 'operation, pipline, task, middleware',
  `content` longtext NOT NULL COMMENT '代码文本',
  `editor` varchar(50) NOT NULL COMMENT '代码editor',
  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_name` (`name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

SET FOREIGN_KEY_CHECKS = 1;

INSERT INTO `bspider_customcode`(`name`, `description`, `type`, `content`, `editor`) VALUES ('ProjectHealthAlertTask', '定时检查各个抓取任务健康状态的脚本', 'operation', '\"\"\"a task template\"\"\"\nfrom bspider.bcron import BaseOperation\nfrom bspider.config import FrameSettings\nfrom bspider.utils.database.mysql import MysqlHandler\nfrom bspider.utils.notify import ding\nfrom bspider.utils.system import System\n\n\nclass ProjectHealthAlertTask(BaseOperation):\n    \"\"\"\n    各个抓取任务健康检查\n    \"\"\"\n\n    def execute_task(self):\n        \"\"\"do you work to produce start urls\"\"\"\n        frame_settings = FrameSettings()\n        downloader_status_table = frame_settings[\'DOWNLOADER_STATUS_TABLE\']\n        parser_status_table = frame_settings[\'PARSER_STATUS_TABLE\']\n\n        self.handler = MysqlHandler(frame_settings[\'WEB_STUDIO_DB\'])\n\n        parser_data = self.__do_query(parser_status_table, \'`status` is not null\')\n        \n        msg = dict()\n\n        for info in parser_data:\n            if info[\'exce_num\'] == 0:\n                continue\n\n            per = info[\'exce_num\'] / info[\'total_num\']\n            \n            msg[info[\'project_id\']] = [info[\'project_name\'], f\'P.ERR:{per:.2%}\', \'\']\n            \n        downloader_data = self.__do_query(downloader_status_table, \'`status` != 200\')\n\n        for info in downloader_data:\n            if info[\'exce_num\'] == 0:\n                continue\n\n            per = info[\'exce_num\'] / info[\'total_num\']\n            if per < 0.1:\n                self.log.info(\'project {} exce_per < 0.1 is {}\'.format(info[\'project_name\'], per))\n                continue\n            if info[\'project_id\'] in msg:\n                msg[info[\'project_id\']][2] = f\'D.ERR:{per:.2%}\'\n            \n            else:\n                msg[info[\'project_id\']] = (info[\'project_name\'], \'\', f\'D.ERR:{per:.2%}\')\n                \n        if len(msg):\n            tmp = list()\n            for project_id, m in msg.items():\n                tmp.append(\'> {}-{} EXEC: {} {}\'.format(project_id, *m))\n            ding(\'\\n\'.join(tmp), \'project exception\')\n            self.log.info(f\'send project exception alert msg: {msg}\')\n            return\n        self.log.info(f\'check project health success: all project is best!\')\n\n    def __do_query(self, table, expr):\n        sql = f\'SELECT `project_id`,`project_name`, \' \\\n              f\'COUNT(IF ({expr}, TRUE, NULL)) AS exce_num, \' \\\n              f\'COUNT(1) AS total_num \' \\\n              f\'FROM {table} \' \\\n              f\'WHERE `create_time`> now()-INTERVAL 15 MINUTE GROUP BY `project_id`;\'\n\n        infos = self.handler.select(sql)\n        return infos\n', 'baii');
INSERT INTO `bspider_customcode`(`name`, `description`, `type`, `content`, `editor`) VALUES ('MySQLSaverPipeline', '异步MySQLsaver Pipeline, 将MySQLSaverItem中的字典类型数据进行存储', 'pipeline', '\"\"\"a pipeline template\"\"\"\nfrom bspider.parser import BasePipeline, MySQLSaverItem\nfrom bspider.utils.exceptions import ParserError\nfrom bspider.utils.database.mysql import AioMysqlHandler, prepare_insert_sql\n\n\nclass MySQLSaverPipeline(BasePipeline):\n\n    def __init__(self, settings, log):\n        super().__init__(settings, log)\n        # 实例化MySQL操作对象\n        db_config = settings.get(\"MYSQL_SAVER_CONFIG\")\n        self.mysql_handler = dict()\n        if db_config is None:\n            raise ParserError(\'MYSQL_SAVER_CONFIG must be set in settings.\')\n\n        for config in db_config:\n            self.mysql_handler[config[\'MYSQL_DB\']] = AioMysqlHandler(config)\n\n    async def process_item(self, item):\n        \"\"\"\n        对item进行处理,各个pipeline重写\n        可以yield返回也可以return\n        返回类型为自订定义的类型，会传递给后面的pipeline，返回None将会丢弃这个item\n        :param item: previous pipeline result\n        :return: param to next pipeline\n        \"\"\"\n        if isinstance(item, MySQLSaverItem):\n            sql, values = prepare_insert_sql(item.table, item.capacity, auto_update=item.auto_update)\n            if not item.db in self.mysql_handler:\n                raise ParserError(f\'Invalid db name at:{item}\')\n\n            await self.mysql_handler[item.db].insert(sql, values)\n            self.log.info(f\'insert success->{item}\')\n        return item\n', 'baii');
INSERT INTO `bspider_customcode`(`name`, `description`, `type`, `content`, `editor`) VALUES ('NodeStatusAlertOperation', '各个节点探活和状态回报脚本，每执行一次轮询所有节点状态', 'operation', '# @Time    : 2019/11/28 6:02 下午\n# @Author  : baii\n# @File    : node_status_alert_task\n# @Use     :\nimport sys\nimport traceback\n\nfrom bspider.bcron import BaseOperation\nfrom bspider.config import FrameSettings\nfrom bspider.core.api import AgentMixIn\nfrom bspider.utils.database.mysql import MysqlHandler\nfrom bspider.utils.exceptions import RemoteOPError\nfrom bspider.utils.notify import ding\nfrom bspider.utils.tools import make_fields_values\n\n\nclass NodeStatusAlertOperation(BaseOperation):\n    \"\"\"\n    集群各节点的健康检查\n    \"\"\"\n\n    def execute_task(self):\n        frame_settings = FrameSettings()\n        node_table = frame_settings[\'NODE_TABLE\']\n        node_status_table = frame_settings[\'NODE_STATUS_TABLE\']\n        handler = MysqlHandler(frame_settings[\'WEB_STUDIO_DB\'])\n\n        sql = f\"select `id`, `ip` from {node_table} where `status` = 1\"\n\n        node_list = handler.select(sql)\n\n        mixin = AgentMixIn()\n        msg = list()\n\n        for node in node_list:\n            data = {\n                \'ip\': node[\'ip\'],\n                \'cpu\': 0,\n                \'memory\': 0,\n                \'disk\': 0\n            }\n            try:\n                # {\"cpu_num\": 1, \"cpu_percent\": 2.6, \"mem_size\": 1.8331985473632812, \"mem_percent\": 58.3, \"disk_size\": 49.214473724365234, \"disk_percent\": 48.6}\n                tmp = mixin.op_get_node_status(node[\'ip\'])\n                data[\'cpu\'] = tmp[\'cpu_percent\']\n                data[\'memory\'] = tmp[\'mem_percent\']\n                data[\'disk\'] = tmp[\'disk_percent\']\n                self.log.info(\'check {ip} success\'.format(**node))\n            except RemoteOPError:\n                e_msg = \'\'.join(traceback.format_exception(*sys.exc_info()))\n                self.log.info(e_msg)\n                msg.append(\'> {ip} heartbeat FATAL\'.format(**node))\n\n            fields, values = make_fields_values(data)\n            sql = f\"insert into {node_status_table} set {fields};\"\n            handler.insert(sql, values)\n\n            self.log.debug(f\'insert node data success! {values}\')\n\n\n        self.log.info(\'heartbeat check finished\')\n        if len(msg):\n            ding(\'\\n\'.join(msg), \'node exception\')\n', 'baii');
INSERT INTO `bspider_customcode`(`name`, `description`, `type`, `content`, `editor`) VALUES ('AutoClearOperation', '自动清理各种status表并保留近7天记录 保留最近7天记录', 'operation', '# @Time    : 2019/11/28 6:20 下午\n# @Author  : baii\n# @File    : auto_delete_task\n# @Use     :\nimport datetime\n\nfrom bspider.bcron import BaseOperation\nfrom bspider.config import FrameSettings\nfrom bspider.utils.database.mysql import MysqlHandler\nfrom bspider.utils.notify import ding\n\n\nclass AutoClearOperation(BaseOperation):\n    \"\"\"\n    自动清理各种status表并保留近7天记录\n    \"\"\"\n    def execute_task(self):\n        \"\"\"do you work to produce start urls\"\"\"\n        frame_settings = FrameSettings()\n        tables = {\n            frame_settings[\'DOWNLOADER_STATUS_TABLE\']: \'`project_id`,`project_name`,`sign`,`method`,`data`,`url`,`status`,`url_sign`,`exception`,`response`,`create_time`\',\n            frame_settings[\'PARSER_STATUS_TABLE\']: \'`project_id`,`project_name`,`sign`,`method`,`data`,`url`,`status`,`url_sign`,`exception`,`response`,`create_time`\',\n            frame_settings[\'NODE_STATUS_TABLE\']: \'`ip`,`memory`,`cpu`,`disk`,`create_time`\',\n        }\n        handler = MysqlHandler(frame_settings[\'WEB_STUDIO_DB\'])\n        msg = list()\n\n        for table, fields in tables.items():\n            try:\n\n                with handler.session() as session:\n                    for sql in [\n                        f\"create table {table}_new like {table};\",\n                        f\"ALTER TABLE {table} RENAME TO {table}_bak;\",\n                        f\"ALTER TABLE {table}_new RENAME TO {table};\"\n                    ]:\n                        session.query(sql)\n\n                start_time = datetime.datetime.now()\n                stop_time = start_time - datetime.timedelta(days=7)\n\n                while start_time > stop_time:\n                    max_time = start_time.strftime(\'%Y-%m-%d %H:%M:%S\')\n                    start_time = start_time - datetime.timedelta(minutes=20)\n                    min_time = start_time.strftime(\'%Y-%m-%d %H:%M:%S\')\n\n                    sql = f\"insert ignore into {table} ({fields}) \" \\\n                          f\"select {fields} from {table}_bak \" \\\n                          f\"where `create_time`> \'{min_time}\' AND `create_time`< \'{max_time}\';\"\n\n                    handler.insert(sql)\n\n                    self.log.info(f\"data {min_time} - {max_time} insert {table} success!\")\n\n                # 需要再优化\n                delete_sql = f\"DROP TABLE {table}_bak;\"\n                handler.delete(delete_sql)\n                self.log.info(f\'{table} clear success!\')\n            except Exception as e:\n                msg.append(f\'> {table} clear failed->{e}!\')\n\n\n        if len(msg):\n            ding(\'\\n\'.join(msg), \'clear exception\')\n            self.log.info(f\'send table clear exception alert msg: {msg}\')\n', 'baii');